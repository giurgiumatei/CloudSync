version: '3.8'

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports:
      - "5001:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ConnectionStrings__AzureConnection=Host=azure-db;Database=AzureDb;Username=sa;Password=P@ssw0rd;
      - ConnectionStrings__AwsConnection=Host=aws-db;Database=AwsDb;Username=sa;Password=P@ssw0rd;
      - Kafka__BootstrapServers=kafka:29092
      - ASPNETCORE_URLS=http://+:80
      # Performance optimizations
      - DOTNET_GCServer=1
      - DOTNET_GCConcurrent=1
      - DOTNET_GCRetainVM=1
    depends_on:
      db-init:
        condition: service_completed_successfully
      aws-consumer:
        condition: service_healthy
      azure-consumer:
        condition: service_healthy
    restart: unless-stopped
    # Resource limits for consistent performance testing
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
    # Network optimizations
    sysctls:
      net.core.somaxconn: 65535
      net.ipv4.tcp_tw_reuse: 1
      net.ipv4.tcp_fin_timeout: 30
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  perftest:
    build:
      context: .
      dockerfile: Dockerfile.perftest
    environment:
      - API_BASE_URL=http://api:80
      - DOTNET_GCServer=1
      - DOTNET_ThreadPool_UnfairSemaphoreSpinLimit=6
    depends_on:
      api:
        condition: service_healthy
    volumes:
      - ./performance-results:/app/results
    restart: "no" # Don't restart performance tests automatically
    # High resource limits for load generation
    deploy:
      resources:
        limits:
          cpus: '6.0'
          memory: 8G
        reservations:
          cpus: '4.0'
          memory: 4G
    # Network optimizations for high throughput
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    sysctls:
      net.core.somaxconn: 65535
      net.ipv4.ip_local_port_range: "1024 65535"
      net.ipv4.tcp_tw_reuse: 1

  # Azure Database (ARM64 compatible - PostgreSQL)
  azure-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: AzureDb
      POSTGRES_USER: sa
      POSTGRES_PASSWORD: YourStrong@Passw0rd
    ports:
      - "5434:5432"
    restart: unless-stopped
    # Database performance optimizations
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    volumes:
      - azure_postgres_data:/var/lib/postgresql/data
      - ./Scripts/init-azure-db.sql:/docker-entrypoint-initdb.d/init-azure-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sa -d AzureDb"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  # AWS Database (ARM64 compatible - PostgreSQL)
  aws-db:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: AwsDb
      POSTGRES_USER: sa
      POSTGRES_PASSWORD: YourStrong@Passw0rd
    ports:
      - "5433:5432"
    restart: unless-stopped
    # Database performance optimizations
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    volumes:
      - aws_postgres_data:/var/lib/postgresql/data
      - ./Scripts/init-aws-db.sql:/docker-entrypoint-initdb.d/init-aws-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U sa -d AwsDb"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s

  # Database initializer service (PostgreSQL)
  db-init:
    image: postgres:15-alpine
    depends_on:
      - azure-db
      - aws-db
    volumes:
      - ./Scripts:/scripts:ro
    environment:
      - POSTGRES_PASSWORD=YourStrong@Passw0rd
    command: >
      bash -c "
        echo 'Waiting for databases to be ready...' &&
        sleep 10 &&
        echo 'Initializing Azure database...' &&
        PGPASSWORD=YourStrong@Passw0rd psql -h azure-db -U sa -d AzureDb -f /scripts/init-azure-db.sql &&
        echo 'Initializing AWS database...' &&
        PGPASSWORD=YourStrong@Passw0rd psql -h aws-db -U sa -d AwsDb -f /scripts/init-aws-db.sql &&
        echo 'Database initialization completed successfully!'
      "
    restart: "no"

  # Kafka infrastructure for high-throughput message processing
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc localhost 2181 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      # High throughput optimizations
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      # Performance tuning
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_LOG_CLEANUP_POLICY: delete
    restart: unless-stopped
    volumes:
      - kafka-data:/var/lib/kafka/data
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G
        reservations:
          cpus: '2.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Kafka topic initialization
  kafka-init:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - kafka
      - db-init
    command: >
      bash -c "
        echo 'Waiting for Kafka to be ready...' &&
        sleep 10 &&
        echo 'Creating Kafka topics...' &&
        kafka-topics --create --topic data-topic --bootstrap-server kafka:29092 --partitions 12 --replication-factor 1 --config min.insync.replicas=1 --config retention.ms=604800000 --config segment.ms=86400000 --config compression.type=lz4 &&
        kafka-topics --create --topic data-topic-dlq --bootstrap-server kafka:29092 --partitions 4 --replication-factor 1 --config min.insync.replicas=1 --config retention.ms=2419200000 &&
        echo 'Kafka topics created successfully!' &&
        echo 'Verifying topics exist...' &&
        kafka-topics --list --bootstrap-server kafka:29092 &&
        echo 'Kafka initialization completed!'
      "
    restart: "no"

  # AWS Kafka Consumer Service
  aws-consumer:
    build:
      context: .
      dockerfile: CloudSync.KafkaAwsConsumer/Dockerfile
    depends_on:
      - db-init
      - kafka-init
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ConnectionStrings__AwsConnection=Host=aws-db;Database=AwsDb;Username=sa;Password=YourStrong@Passw0rd;
      - Kafka__BootstrapServers=kafka:29092
      - ASPNETCORE_URLS=http://+:80
    ports:
      - "8082:80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Azure Kafka Consumer Service
  azure-consumer:
    build:
      context: .
      dockerfile: Dockerfile.azure-consumer
    depends_on:
      - db-init
      - kafka-init
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ConnectionStrings__AzureConnection=Host=azure-db;Database=AzureDb;Username=sa;Password=YourStrong@Passw0rd;
      - Kafka__BootstrapServers=kafka:29092
      - ASPNETCORE_URLS=http://+:80
    ports:
      - "8083:80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Optional monitoring service for performance insights
  monitoring:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped
    profiles:
      - monitoring

volumes:
  azure_postgres_data:
  aws_postgres_data:
  prometheus-data:
  kafka-data:

networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1500